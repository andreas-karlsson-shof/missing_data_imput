{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8def207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Packages\n"
     ]
    }
   ],
   "source": [
    "from    imputation      import  core_utils, core_imputation_model\n",
    "import  numpy           as      np\n",
    "#from    tqdm.notebook   import  tqdm\n",
    "from    tqdm import tqdm\n",
    "print(\"Imported Packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd5d4d0",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8d4782",
   "metadata": {},
   "source": [
    "`core_utils.get_data_panel` loads the data from the corresponding `data_path`, which is a feather file shared on Google drive. We have to use Gdrive as it is too large to host on Github. The data file it contains the characteristic percentile ranks as a numpy array of shape TxNxL where T is the number of dates, N the number of stocks, and L the number of characteristics. The file also includes the raw characteristics, the characteristic namess, the dates and permnos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0395d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/example_data.fthr\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/example_data.fthr\"\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55b9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_rank_chars, chars, date_vals, permnos = core_utils.get_data_panel(\n",
    "    path=data_path, computstat_data_present_filter=True,start_date=19770000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aac6105a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345367\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(percentile_rank_chars).sum()) # number of missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2d413f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_groupings = core_utils.CHAR_GROUPINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16149d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A2ME', 'Q'), ('AC', 'Q'), ('AT', 'Q'), ('ATO', 'Q'), ('B2M', 'QM'), ('BETA_d', 'M'), ('BETA_m', 'M'), ('C2A', 'Q'), ('CF2B', 'Q'), ('CF2P', 'QM'), ('CTO', 'Q'), ('D2A', 'Q'), ('D2P', 'M'), ('DPI2A', 'Q'), ('E2P', 'QM'), ('FC2Y', 'QY'), ('IdioVol', 'M'), ('INV', 'Q'), ('LEV', 'Q'), ('ME', 'M'), ('TURN', 'M'), ('NI', 'Q'), ('NOA', 'Q'), ('OA', 'Q'), ('OL', 'Q'), ('OP', 'Q'), ('PCM', 'Q'), ('PM', 'Q'), ('PROF', 'QY'), ('Q', 'QM'), ('R2_1', 'M'), ('R12_2', 'M'), ('R12_7', 'M'), ('R36_13', 'M'), ('R60_13', 'M'), ('HIGH52', 'M'), ('RVAR', 'M'), ('RNA', 'Q'), ('ROA', 'Q'), ('ROE', 'Q'), ('S2P', 'QM'), ('SGA2S', 'Q'), ('SPREAD', 'M'), ('SUV', 'M'), ('VAR', 'M')]\n"
     ]
    }
   ],
   "source": [
    "print(char_groupings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5efa811",
   "metadata": {},
   "source": [
    "# Running Imputations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fa15f6",
   "metadata": {},
   "source": [
    "In this section we will run the imputation method described in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36889c6",
   "metadata": {},
   "source": [
    "Two methods we want to highlight are\n",
    "- `core_imputation_model_new.run_imputation`\n",
    "- `core_imputation_model_new.fit_factors_and_loadings`\n",
    "\n",
    "The first code runs the full method as described in the paper, including potentially different time series information sets depending on the arguments given.\n",
    "\n",
    "The second code estimates the XS factor model. \n",
    "\n",
    "The examples below correspond to global and local fits. The parameters are documented in the function definition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a3ba60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T = 12, N = 4469, L = 45\n"
     ]
    }
   ],
   "source": [
    "T, N, L = percentile_rank_chars.shape\n",
    "print(f\"T = {T:d}, N = {N:d}, L = {L:d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f7023",
   "metadata": {},
   "source": [
    "## Estimating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52a8e1",
   "metadata": {},
   "source": [
    "We start with the local estimation. In this case, we show how to estimate either the purely cross-sectional model (local XS) or the cross-sectional model with backwards time series information (local B-XS). \n",
    "\n",
    "We would like to emphasize two parameters in this estimation. This first is the number of cross-sectional factors K: `n_xs_factors` the second is the cross-sectional factor regularization gamma: `xs_factor_reg`.\n",
    "\n",
    "These two hyperparameters have a significant impact on the performance of the model, and should be selected carefully. The parameters we use in this example are selected for the data-set from Missing Financial Data, and should not be considered default aprameters for alternative data-sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5edbc0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: kernel kernelspec migrate run troubleshoot\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n"
     ]
    }
   ],
   "source": [
    "#!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a59a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done   4 out of  12 | elapsed:   15.0s remaining:   30.1s\n",
      "[Parallel(n_jobs=30)]: Done   7 out of  12 | elapsed:   15.0s remaining:   10.7s\n",
      "[Parallel(n_jobs=30)]: Done  10 out of  12 | elapsed:   15.0s remaining:    2.9s\n",
      "[Parallel(n_jobs=30)]: Done  12 out of  12 | elapsed:   15.0s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9381ff3678cc404d9e96410a387e1f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resids rmse are  0.09522440538615277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8d90b850714e6e8dda67645fa915cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imputation = core_imputation_model.impute_data_xs(\n",
    "    percentile_rank_chars, \n",
    "    n_xs_factors            = 20,\n",
    "    time_varying_loadings   = True,\n",
    "    xs_factor_reg           = 0.01 / L,\n",
    "    min_xs_obs              = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80c2b180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148725\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(imputation).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81a12d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done   4 out of  12 | elapsed:    7.3s remaining:   14.6s\n",
      "[Parallel(n_jobs=30)]: Done   7 out of  12 | elapsed:    7.3s remaining:    5.2s\n",
      "[Parallel(n_jobs=30)]: Done  10 out of  12 | elapsed:    7.3s remaining:    1.4s\n",
      "[Parallel(n_jobs=30)]: Done  12 out of  12 | elapsed:    7.3s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb82c2e38cb94bf7bb775a739f830988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resids rmse are  0.09522440538615277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e08a702196499aba9417da04d8e36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c97ebec31fa4cba9ec70906a77e9851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54129898830b4ab5aabd15b88f9c73f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bw_xs_imputation = core_imputation_model.impute_data_bxs(\n",
    "    percentile_rank_chars, \n",
    "    n_xs_factors=20,\n",
    "    time_varying_loadings=True,\n",
    "    xs_factor_reg=0.01 / L,\n",
    "    min_xs_obs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7697f1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(503775)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.isnan(bw_xs_imputation).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "290ddd06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done   4 out of  12 | elapsed:   12.9s remaining:   26.0s\n",
      "[Parallel(n_jobs=30)]: Done   7 out of  12 | elapsed:   13.0s remaining:    9.2s\n",
      "[Parallel(n_jobs=30)]: Done  10 out of  12 | elapsed:   13.0s remaining:    2.5s\n",
      "[Parallel(n_jobs=30)]: Done  12 out of  12 | elapsed:   13.0s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d273086dfe478793d4129189f8731c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resids rmse are  0.09522440538615277\n"
     ]
    }
   ],
   "source": [
    "gamma_ts, lmbda = core_imputation_model.fit_factors_and_loadings(\n",
    "    char_panel=percentile_rank_chars, \n",
    "    min_chars=1, \n",
    "    K=20, \n",
    "    num_months_train=T,\n",
    "    reg=0.01 / L,\n",
    "    time_varying_lambdas=True,\n",
    "    eval_data=None,\n",
    "    run_in_parallel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a516f99",
   "metadata": {},
   "source": [
    "# On the Selction of the Number of Factors and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83080899",
   "metadata": {},
   "source": [
    "Below we show the plots from Figures 8 \\& 9 in the paper. These figures illustrate how to determine the optimal regularization and number of factors. In more detail, we evaluate the out-of-sample performance of the model for different number of factors and regularization across a grid of these choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5051b0",
   "metadata": {},
   "source": [
    "![example_of_cval.png](data/example_of_cval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d1e86b",
   "metadata": {},
   "source": [
    "![reg_cval.png](data/reg_cval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cd093a",
   "metadata": {},
   "source": [
    "The `core_imputation_model_new.fit_factors_and_loadings` method allows to pass on an argument `eval_data`. This, if provided, is compared against the imputation and the RMSE is reported. This is a simple way for evaluating the tuning parameter choice (number of factors and regularization) for the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
